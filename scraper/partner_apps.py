# -*- coding: utf-8 -*-
"""shopify_review.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17hJavI_chbKYBR1EK-XTxbuo1BLOrJxE
"""

import requests
from bs4 import BeautifulSoup
from bs4 import Tag
import pandas as pd
from datetime import datetime
import time
import random

def fetch_shopify_apps(base_url):
    """Fetch all apps from a Shopify developer page."""
    apps = []
    response = requests.get(base_url)
    soup = BeautifulSoup(response.content, 'html.parser')
    divs = soup.select('div.tw-text-body-sm.tw-font-link')

    for div in divs:
        app_name = div.find('a').text.strip()
        app_url = div.find('a')['href']
        if not app_url.startswith('http'):
            app_url = f"https://apps.shopify.com{app_url}"
        apps.append({'name': app_name, 'url': app_url})

    print(f"âœ… Found {len(apps)} apps.")
    return apps

def extract_rating(review):
    """Extract star rating from the review."""
    rating_div = review.find('div', class_='tw-flex tw-relative tw-space-x-0.5 tw-w-[88px] tw-h-md')
    if rating_div and 'aria-label' in rating_div.attrs:
        aria_label = rating_div['aria-label']
        try:
            return aria_label.split(' ')[0]
        except IndexError:
            return None
    return None

def parse_review_date(date_str):
    """Convert Shopify date format into a Python datetime object."""
    if 'Edited' in date_str:
        date_str = date_str.split('Edited')[1].strip()
    else:
        date_str = date_str.split('Edited')[0].strip()
    try:
        return datetime.strptime(date_str, '%B %d, %Y')
    except ValueError:
        return None

def fetch_reviews(app_url, app_name, start_date, end_date):
    """Fetch all reviews for a given Shopify app."""
    base_url = app_url.split('?')[0]
    page = 1
    reviews = []

    while True:  # Keep fetching until old reviews are encountered
        print(f"Fetching page {page} for {app_name}...")
        reviews_url = f"{base_url}/reviews?sort_by=newest&page={page}"
        response = requests.get(reviews_url)
        soup = BeautifulSoup(response.content, 'html.parser')

        # Updated review container class (Shopify structure update)
        review_divs = soup.find_all("div", attrs={"data-merchant-review": True})
        print(f"ðŸ”¹ Found {len(review_divs)} reviews on page {page}")

        if not review_divs:  # If no reviews are found, break the loop
            print('âŒ No more reviews found. Stopping.')
            break

        has_recent_reviews = False

        for review_div in review_divs:
            review_text_div = review_div.find('div', {'data-truncate-content-copy': True})
            review_text = review_text_div.find('p').text.strip() if review_text_div else "No review text"

            reviewer_name_div = review_div.find('div', class_='tw-text-heading-xs tw-text-fg-primary tw-overflow-hidden tw-text-ellipsis tw-whitespace-nowrap')
            reviewer_name = reviewer_name_div.text.strip() if reviewer_name_div else "No reviewer name"

            review_date_div = review_div.find('div', class_='tw-text-body-xs tw-text-fg-tertiary')
            review_date_str = review_date_div.text.strip() if review_date_div else "No review date"

            reviewer_and_location_div = reviewer_name_div.parent
            reviewer_and_location_div_children = [child for child in reviewer_and_location_div.contents if isinstance(child, Tag)]
            location = reviewer_and_location_div_children[1].text.strip() if len(reviewer_and_location_div_children) > 1 else 'N/A'
            duration = reviewer_and_location_div_children[2].text.strip() if len(reviewer_and_location_div_children) > 2 else 'N/A'

            if duration.endswith(' using the app'):
                duration = duration[:-len(' using the app')]

            rating = extract_rating(review_div)
            review_date = parse_review_date(review_date_str)

            if review_date and review_date > start_date:
                has_recent_reviews = True
                continue
            elif review_date and start_date >= review_date >= end_date:
                # Filter reviews based on date range
                reviews.append({
                    'app_name': app_name,
                    'review': review_text,
                    'reviewer': reviewer_name,
                    'date': review_date_str,
                    'location': location,
                    'duration': duration,
                    'rating': rating
                })
                has_recent_reviews = True
            else:
                print(f"ðŸ›‘ Review too old: {review_date_str}. Stopping.")
                break  # Stop scraping if we reach an older review

        if not has_recent_reviews:
            print('âœ… All recent reviews collected.')
            break

        page += 1  # Go to the next page

        time.sleep(random.uniform(1.2, 3.0))  # âœ… Prevents rate limiting by adding a delay

    return reviews

# base_url = 'https://apps.shopify.com/partners/cedcommerce'
# base_url = 'https://apps.shopify.com/partners/tanishqandmac'
# base_url = 'https://apps.shopify.com/partners/digital-product-labs'
# base_url = 'https://apps.shopify.com/partners/etsify-io'  
# base_url = 'https://apps.shopify.com/partners/common-services'
base_url = 'https://apps.shopify.com/partners/ecom-planners2'
# base_url = 'https://apps.shopify.com/partners/litcommerce1'

# Date Range for Reviews
start_date = datetime(2025, 5, 9)
end_date = datetime(2017, 1, 1)

def main():
    """Main function to fetch reviews for all Shopify apps under a developer."""
    apps = fetch_shopify_apps(base_url)

    print(f"ðŸ”¹ Total Apps Found: {len(apps)}")

    app_reviews = {}
    for app in apps:
        reviews = fetch_reviews(app['url'], app['name'], start_date, end_date)
        app_reviews[app['name']] = reviews

    print(f"ðŸ”¹ Total Apps with Reviews: {len(app_reviews)}")

    data = []
    for app_name, reviews in app_reviews.items():
        for review in reviews:
            row_data = {
                'app_name': app_name,
                'review': review.get('review', 'No review'),
                'reviewer': review.get('reviewer', 'No reviewer'),
                'date': review.get('date', 'No date'),
                'rating': review.get('rating', 'No rating'),
                'duration': review.get('duration', 'No duration'),
                'location': review.get('location', 'No location'),
            }
            data.append(row_data)

    print(f"ðŸ”¹ Total Reviews Collected: {len(data)}")

    df = pd.DataFrame(data)
    now = datetime.now()
    csv_file_path = f'shopify_app_reviews_{now.strftime("%Y%m%d")}.csv'
    df.to_csv(csv_file_path, index=False, encoding='utf-8')

    print("âœ… Data has been written to shopify_app_reviews.csv")

if __name__ == '__main__':
    main()